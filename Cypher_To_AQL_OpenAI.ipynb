{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training and Finetuning ChatGPT 3.5 model for Cypher to ArangoDB conversion\n",
    "\n",
    "## Prerequisites: \n",
    "1. OpenAI API key please set in your environment as OPENAI_API_KEY\n",
    "2. Sample queries for Cypher Translated to AQL to train on (This notebook contains some samples, but they will vary depending upon your use case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training / Tuning Dataset\n",
    "This is the training data to fine tune the model. The format is as follows:\n",
    "* desc_X : Description of the query\n",
    "* cypher_ex_X : Example of Cypher query\n",
    "* aql_tr_X: Translated AQL query for the Cypher query\n",
    "\n",
    "You can potentially read these and your own examples from a file. Initially you may have to manually or in a semi-automated fashion (using Chat GPT) convert your Cypher queries to AQL queries. As your training/fine tuning gets better , the less manual intervention would be required for your query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find all friends of a person named \"Alice\" and return their names\n",
    "dataset = {\n",
    "\"desc_1\" :\"Find all friends of a person named Alice and return their names\",\n",
    "    \n",
    "\"cypher_ex_1\" : \"\"\"\n",
    "MATCH (p:Person)-[:FRIEND]->(f:Person)\n",
    "WHERE p.name = 'Alice'\n",
    "RETURN p.name, f.name\n",
    "\"\"\",\n",
    "\n",
    "\"aql_tr_1\": \"\"\"\n",
    "FOR p IN Person\n",
    "    FOR f IN 1..1 OUTBOUND p FRIEND\n",
    "    FILTER p.name == 'Alice'\n",
    "    RETURN { pName: p.name, fName: f.name }\n",
    "\"\"\",\n",
    "\n",
    "\"desc_2\": \"Find Movies Directed by a Specific Director\",\n",
    "\n",
    "\"cypher_ex_2\": \"\"\"\n",
    "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
    "WHERE d.name = 'Steven Spielberg'\n",
    "RETURN m.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_2\": \"\"\"\n",
    "FOR d IN Director\n",
    "    FOR m IN 1..1 OUTBOUND d DIRECTED\n",
    "    FILTER d.name == 'Steven Spielberg'\n",
    "    RETURN m.title\n",
    "\"\"\",\n",
    "\n",
    "\"desc_3\": \"Find Employees Managed by a Specific Manager\",\n",
    "\n",
    "\"cypher_ex_3\": \"\"\"\n",
    "MATCH (manager:Employee)-[:MANAGES]->(employee:Employee)\n",
    "WHERE manager.name = 'John Doe'\n",
    "RETURN employee.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_3\": \"\"\"\n",
    "FOR manager IN Employee\n",
    "    FOR employee IN 1..1 OUTBOUND manager MANAGES\n",
    "    FILTER manager.name == 'John Doe'\n",
    "    RETURN employee.name\n",
    "\"\"\",\n",
    "\n",
    "\"desc_4\": \"Find All Authors of a Book\",\n",
    "\n",
    "\"cypher_ex_4\": \"\"\"\n",
    "MATCH (a:Author)-[:WROTE]->(b:Book)\n",
    "WHERE b.title = 'The Great Gatsby'\n",
    "RETURN a.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_4\": \"\"\"\n",
    "FOR a IN Author\n",
    "    FOR b IN 1..1 OUTBOUND a WROTE\n",
    "    FILTER b.title == 'The Great Gatsby'\n",
    "    RETURN a.name\n",
    "\"\"\",\n",
    "    \n",
    "\n",
    "\"desc_5\": \"Find All Actors Who Starred in a Movie\",\n",
    "    \n",
    "\"cypher_ex_5\": \"\"\"\n",
    "MATCH (a:Actor)-[:ACTED_IN]->(m:Movie)\n",
    "WHERE m.title = 'Inception'\n",
    "RETURN a.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_5\": \"\"\"\n",
    "FOR a IN Actor\n",
    "    FOR m IN 1..1 OUTBOUND a ACTED_IN\n",
    "    FILTER m.title == 'Inception'\n",
    "    RETURN a.name\n",
    "\"\"\",\n",
    "\n",
    "\n",
    "\"desc_6\": \"Find All Products Purchased by a Customer\",\n",
    "    \n",
    "\"cypher_ex_6\": \"\"\"\n",
    "MATCH (c:Customer)-[:PURCHASED]->(p:Product)\n",
    "WHERE c.username = 'johndoe'\n",
    "RETURN p.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_6\": \"\"\"\n",
    "FOR c IN Customer\n",
    "    FOR p IN 1..1 OUTBOUND c PURCHASED\n",
    "    FILTER c.username == 'johndoe'\n",
    "    RETURN p.name\n",
    "\"\"\",\n",
    "    \n",
    "\n",
    "\"desc_7\": \"Find All Cities Connected to a Specific Airport\",\n",
    "    \n",
    "\"cypher_ex_7\": \"\"\"\n",
    "MATCH (a:Airport)-[:CONNECTS_TO]->(c:City)\n",
    "WHERE a.code = 'JFK'\n",
    "RETURN c.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_7\": \"\"\"\n",
    "FOR a IN Airport\n",
    "    FOR c IN 1..1 OUTBOUND a CONNECTS_TO\n",
    "    FILTER a.code == 'JFK'\n",
    "    RETURN c.name\n",
    "\"\"\",\n",
    "    \n",
    "\n",
    "\"desc_8\": \"Find All Products in a Specific Category\",\n",
    "    \n",
    "\"cypher_ex_8\": \"\"\"\n",
    "MATCH (c:Category)<-[:IN_CATEGORY]-(p:Product)\n",
    "WHERE c.name = 'Electronics'\n",
    "RETURN p.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_8\": \"\"\"\n",
    "FOR c IN Category\n",
    "    FOR p IN 1..1 INBOUND c IN_CATEGORY\n",
    "    FILTER c.name == 'Electronics'\n",
    "    RETURN p.name\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_9\": \"Find All Courses Taught by a Specific Professor\",\n",
    "    \n",
    "\"cypher_ex_9\": \"\"\"\n",
    "MATCH (p:Professor)-[:TEACHES]->(c:Course)\n",
    "WHERE p.name = 'Dr. Smith'\n",
    "RETURN c.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_9\": \"\"\"\n",
    "FOR p IN Professor\n",
    "    FOR c IN 1..1 OUTBOUND p TEACHES\n",
    "    FILTER p.name == 'Dr. Smith'\n",
    "    RETURN c.title\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_10\": \"Find All Ingredients Used in a Recipe\",\n",
    "\n",
    "\"cypher_ex_10\": \"\"\"\n",
    "MATCH (r:Recipe)-[:USES]->(i:Ingredient)\n",
    "WHERE r.name = 'Spaghetti Carbonara'\n",
    "RETURN i.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_10\": \"\"\"\n",
    "FOR r IN Recipe\n",
    "    FOR i IN 1..1 OUTBOUND r USES\n",
    "    FILTER r.name == 'Spaghetti Carbonara'\n",
    "    RETURN i.name\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_11\": \"Find All Students Enrolled in a Course\",\n",
    "\n",
    "\"cypher_ex_11\": \"\"\"\n",
    "MATCH (s:Student)-[:ENROLLED_IN]->(c:Course)\n",
    "WHERE c.code = 'CS101'\n",
    "RETURN s.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_11\": \"\"\"\n",
    "FOR s IN Student\n",
    "    FOR c IN 1..1 OUTBOUND s ENROLLED_IN\n",
    "    FILTER c.code == 'CS101'\n",
    "    RETURN s.name\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_12\":\"Find All Books Written by an Author\",\n",
    "\n",
    "\"cypher_ex_12\": \"\"\"\n",
    "MATCH (a:Author)-[:WROTE]->(b:Book)\n",
    "WHERE a.name = 'J.K. Rowling'\n",
    "RETURN b.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_12\": \"\"\"\n",
    "FOR a IN Author\n",
    "    FOR b IN 1..1 OUTBOUND a WROTE\n",
    "    FILTER a.name == 'J.K. Rowling'\n",
    "    RETURN b.title\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_13\": \"Find All Employees Reporting to a Manager\",\n",
    "    \n",
    "\"cypher_ex_13\": \"\"\"\n",
    "MATCH (manager:Employee)-[:MANAGES]->(employee:Employee)\n",
    "WHERE manager.name = 'Jane Smith'\n",
    "RETURN employee.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_13\": \"\"\"\n",
    "FOR manager IN Employee\n",
    "    FOR employee IN 1..1 OUTBOUND manager MANAGES\n",
    "    FILTER manager.name == 'Jane Smith'\n",
    "    RETURN employee.name\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_14\": \"Find All Movies Where Two Actors Co-Starred\",\n",
    "    \n",
    "\"cypher_ex_14\": \"\"\"\n",
    "MATCH (a1:Actor)-[:ACTED_IN]->(m:Movie)<-[:ACTED_IN]-(a2:Actor)\n",
    "WHERE a1.name = 'Tom Hanks' AND a2.name = 'Meg Ryan'\n",
    "RETURN m.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_14\": \"\"\"\n",
    "FOR a1 IN Actor\n",
    "    FOR m IN 1..1 OUTBOUND a1 ACTED_IN\n",
    "        FOR a2 IN 1..1 INBOUND m ACTED_IN\n",
    "        FILTER a1.name == 'Tom Hanks' AND a2.name == 'Meg Ryan'\n",
    "        RETURN m.title\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_15\": \"Find All Products Purchased by Frequent Customers\",\n",
    "    \n",
    "\"cypher_ex_15\": \"\"\"\n",
    "MATCH (c:Customer)-[:PURCHASED]->(p:Product)\n",
    "WHERE c.total_purchases > 1000\n",
    "RETURN c.name, p.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_15\": \"\"\"\n",
    "FOR c IN Customer\n",
    "    FILTER c.total_purchases > 1000\n",
    "    FOR p IN 1..1 OUTBOUND c PURCHASED\n",
    "    RETURN { customer: c.name, product: p.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_16\": \"Find All Airports Connected to a City by a Specific Airline\",\n",
    "    \n",
    "\"cypher_ex_16\": \"\"\"\n",
    "MATCH (c:City)<-[:LOCATED_IN]-(a:Airport)-[:OPERATES_BY]->(airline:Airline)\n",
    "WHERE c.name = 'New York' AND airline.name = 'Delta Airlines'\n",
    "RETURN a.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_16\": \"\"\"\n",
    "FOR c IN City\n",
    "    FILTER c.name == 'New York'\n",
    "    FOR a IN 1..1 INBOUND c LOCATED_IN\n",
    "        FOR airline IN 1..1 OUTBOUND a OPERATES_BY\n",
    "        FILTER airline.name == 'Delta Airlines'\n",
    "        RETURN a.name\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_17\": \"Find All Customers Who Bought Products from a Specific Category\",\n",
    "    \n",
    "\"cypher_ex_17\": \"\"\"\n",
    "MATCH (c:Customer)-[:PURCHASED]->(p:Product)-[:IN_CATEGORY]->(cat:Category)\n",
    "WHERE cat.name = 'Electronics'\n",
    "RETURN c.name, p.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_17\": \"\"\"\n",
    "FOR c IN Customer\n",
    "    FOR p IN 1..1 OUTBOUND c PURCHASED\n",
    "        FOR cat IN 1..1 INBOUND p IN_CATEGORY\n",
    "        FILTER cat.name == 'Electronics'\n",
    "        RETURN { customer: c.name, product: p.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_18\": \"Find All Professors Teaching Multiple Courses\",\n",
    "    \n",
    "\"cypher_ex_18\": \"\"\"\n",
    "MATCH (p:Professor)-[:TEACHES]->(c:Course)\n",
    "WITH p, COUNT(c) AS courseCount\n",
    "WHERE courseCount > 1\n",
    "RETURN p.name, courseCount\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_18\": \"\"\"\n",
    "FOR p IN Professor\n",
    "    FOR c IN 1..1 OUTBOUND p TEACHES\n",
    "    COLLECT p, courseCount = LENGTH(c)\n",
    "    FILTER courseCount > 1\n",
    "    RETURN { professor: p.name, courseCount: courseCount }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_19\": \"Find All Cities Connected to a Specific City by Multiple Airlines\",\n",
    "    \n",
    "\"cypher_ex_19\": \"\"\"\n",
    "MATCH (c1:City)-[:CONNECTS_TO]->(c2:City)<-[:CONNECTS_TO]-(a:Airport)-[:OPERATES_BY]->(airline:Airline)\n",
    "WHERE c1.name = 'Los Angeles'\n",
    "WITH c2, airline, COUNT(DISTINCT airline) AS airlineCount\n",
    "WHERE airlineCount > 1\n",
    "RETURN c2.name, airlineCount\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_19\": \"\"\"\n",
    "FOR c1 IN City\n",
    "    FILTER c1.name == 'Los Angeles'\n",
    "    FOR c2 IN 1..1 OUTBOUND c1 CONNECTS_TO\n",
    "        FOR a IN 1..1 INBOUND c2 CONNECTS_TO\n",
    "            FOR airline IN 1..1 OUTBOUND a OPERATES_BY\n",
    "            COLLECT c2, airlineCount = LENGTH(DISTINCT airline)\n",
    "            FILTER airlineCount > 1\n",
    "            RETURN { city: c2.name, airlineCount: airlineCount }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_20\": \"Find All Courses That Share Students\",\n",
    "    \n",
    "\"cypher_ex_20\": \"\"\"\n",
    "MATCH (s:Student)-[:ENROLLED_IN]->(c1:Course)<-[:ENROLLED_IN]-(s2:Student)-[:ENROLLED_IN]->(c2:Course)\n",
    "WHERE c1 <> c2\n",
    "RETURN s.name, c1.title, c2.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_20\": \"\"\"\n",
    "FOR s IN Student\n",
    "    FOR c1 IN 1..1 OUTBOUND s ENROLLED_IN\n",
    "        FOR s2 IN 1..1 INBOUND c1 ENROLLED_IN\n",
    "            FOR c2 IN 1..1 OUTBOUND s2 ENROLLED_IN\n",
    "            FILTER c1 != c2\n",
    "            RETURN { student: s.name, course1: c1.title, course2: c2.title }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_21\": \"Find All Companies and Their Employees in a Specific City\",\n",
    "    \n",
    "\"cypher_ex_21\": \"\"\"\n",
    "MATCH (c:Company)-[:EMPLOYS]->(e:Employee)-[:LOCATED_IN]->(city:City)\n",
    "WHERE city.name = 'San Francisco'\n",
    "RETURN c.name, e.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_21\": \"\"\"\n",
    "FOR c IN Company\n",
    "    FOR e IN 1..1 OUTBOUND c EMPLOYS\n",
    "        FOR city IN 1..1 INBOUND e LOCATED_IN\n",
    "        FILTER city.name == 'San Francisco'\n",
    "        RETURN { company: c.name, employee: e.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_22\": \"Find All Authors Who Co-Wrote a Book\",\n",
    "    \n",
    "\"cypher_ex_22\": \"\"\"\n",
    "MATCH (a1:Author)-[:WROTE]->(b:Book)<-[:WROTE]-(a2:Author)\n",
    "WHERE a1 <> a2\n",
    "RETURN a1.name, a2.name, b.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_22\": \"\"\"\n",
    "FOR a1 IN Author\n",
    "    FOR b IN 1..1 OUTBOUND a1 WROTE\n",
    "        FOR a2 IN 1..1 OUTBOUND b WROTE\n",
    "        FILTER a1 != a2\n",
    "        RETURN { author1: a1.name, author2: a2.name, book: b.title }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_23\": \"Find All Movies Directed by Actors\",\n",
    "    \n",
    "\"cypher_ex_23\": \"\"\"\n",
    "MATCH (a:Actor)-[:DIRECTED]->(m:Movie)\n",
    "RETURN a.name, m.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_23\": \"\"\"\n",
    "FOR a IN Actor\n",
    "    FOR m IN 1..1 OUTBOUND a DIRECTED\n",
    "    RETURN { actor: a.name, movie: m.title }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_24\": \"Find All Customers Who Purchased the Same Product\",\n",
    "    \n",
    "\"cypher_ex_24\": \"\"\"\n",
    "MATCH (c1:Customer)-[:PURCHASED]->(p:Product)<-[:PURCHASED]-(c2:Customer)\n",
    "WHERE c1 <> c2\n",
    "RETURN c1.name, c2.name, p.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_24\": \"\"\"\n",
    "FOR c1 IN Customer\n",
    "    FOR p IN 1..1 OUTBOUND c1 PURCHASED\n",
    "        FOR c2 IN 1..1 INBOUND p PURCHASED\n",
    "        FILTER c1 != c2\n",
    "        RETURN { customer1: c1.name, customer2: c2.name, product: p.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_25\": \"Find All Airports That Share the Same City\",\n",
    "    \n",
    "\"cypher_ex_25\": \"\"\"\n",
    "MATCH (a1:Airport)-[:LOCATED_IN]->(city:City)<-[:LOCATED_IN]-(a2:Airport)\n",
    "WHERE a1 <> a2\n",
    "RETURN a1.name, a2.name, city.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_25\": \"\"\"\n",
    "FOR a1 IN Airport\n",
    "    FOR city IN 1..1 INBOUND a1 LOCATED_IN\n",
    "        FOR a2 IN 1..1 OUTBOUND city LOCATED_IN\n",
    "        FILTER a1 != a2\n",
    "        RETURN { airport1: a1.name, airport2: a2.name, city: city.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_26\":\"Find All Professors Who Teach Both Undergraduate and Graduate Courses\",\n",
    "    \n",
    "\"cypher_ex_26\": \"\"\"\n",
    "MATCH (p:Professor)-[:TEACHES]->(c1:Course { level: 'Undergraduate' })<-\n",
    "[:TEACHES]-(p:Professor)-[:TEACHES]->(c2:Course { level: 'Graduate' })\n",
    "RETURN p.name, c1.title, c2.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_26\": \"\"\"\n",
    "FOR p IN Professor\n",
    "    FOR c1 IN 1..1 OUTBOUND p TEACHES\n",
    "        FOR c2 IN 1..1 OUTBOUND p TEACHES\n",
    "        FILTER c1 != c2 AND c1.level == 'Undergraduate' AND c2.level == 'Graduate'\n",
    "        RETURN { professor: p.name, course1: c1.title, course2: c2.title }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_27\": \"Find All Actors Who Have Acted in Movies of a Specific Genre\",\n",
    "    \n",
    "\"cypher_ex_27\": \"\"\"\n",
    "MATCH (a:Actor)-[:ACTED_IN]->(m:Movie)-[:IN_GENRE]->(g:Genre)\n",
    "WHERE g.name = 'Action'\n",
    "RETURN a.name, m.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_27\": \"\"\"\n",
    "FOR a IN Actor\n",
    "    FOR m IN 1..1 OUTBOUND a ACTED_IN\n",
    "        FOR g IN 1..1 OUTBOUND m IN_GENRE\n",
    "        FILTER g.name == 'Action'\n",
    "        RETURN { actor: a.name, movie: m.title }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_28\": \"Find All Customers Who Purchased Products in Multiple Categories\",\n",
    "    \n",
    "\"cypher_ex_28\": \"\"\"\n",
    "MATCH (c:Customer)-[:PURCHASED]->(p1:Product)-[:IN_CATEGORY]->(cat1:Category)<-[:IN_CATEGORY]-(p2:Product)-[:PURCHASED]-(c:Customer)\n",
    "WHERE p1 <> p2\n",
    "RETURN c.name, cat1.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_28\": \"\"\"\n",
    "FOR c IN Customer\n",
    "    FOR p1 IN 1..1 OUTBOUND c PURCHASED\n",
    "        FOR cat1 IN 1..1 INBOUND p1 IN_CATEGORY\n",
    "            FOR p2 IN 1..1 OUTBOUND c PURCHASED\n",
    "            FOR cat2 IN 1..1 INBOUND p2 IN_CATEGORY\n",
    "            FILTER p1 != p2 AND cat1.name != cat2.name\n",
    "            RETURN { customer: c.name, category1: cat1.name, category2: cat2.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_29\": \"Find All Employees Who Supervise Other Employees\",\n",
    "    \n",
    "\"cypher_ex_29\": \"\"\"\n",
    "MATCH (manager:Employee)-[:MANAGES]->(employee:Employee)\n",
    "RETURN manager.name, employee.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_29\": \"\"\"\n",
    "FOR manager IN Employee\n",
    "    FOR employee IN 1..1 OUTBOUND manager MANAGES\n",
    "    RETURN { manager: manager.name, employee: employee.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_30\": \"Find All Employees Who Share the Same Manager\",\n",
    "    \n",
    "\"cypher_ex_30\": \"\"\"\n",
    "MATCH (manager:Employee)-[:MANAGES]->(employee1:Employee)<-[:MANAGES]-(employee2:Employee)\n",
    "WHERE employee1 <> employee2\n",
    "RETURN manager.name, employee1.name, employee2.name\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_30\": \"\"\"\n",
    "FOR manager IN Employee\n",
    "    FOR employee1 IN 1..1 OUTBOUND manager MANAGES\n",
    "        FOR employee2 IN 1..1 INBOUND manager MANAGES\n",
    "        FILTER employee1 != employee2\n",
    "        RETURN { manager: manager.name, employee1: employee1.name, employee2: employee2.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_31\": \"Find All Authors Who Have Co-Authored Multiple Books\",\n",
    "    \n",
    "\"cypher_ex_31\": \"\"\"\n",
    "MATCH (a1:Author)-[:WROTE]->(b1:Book)<-[:WROTE]-(a2:Author)-[:WROTE]->(b2:Book)\n",
    "WHERE a1 <> a2 AND b1 <> b2\n",
    "RETURN a1.name, a2.name, b1.title, b2.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_31\": \"\"\"\n",
    "FOR a1 IN Author\n",
    "    FOR b1 IN 1..1 OUTBOUND a1 WROTE\n",
    "        FOR a2 IN 1..1 OUTBOUND b1 WROTE\n",
    "            FOR b2 IN 1..1 INBOUND a2 WROTE\n",
    "            FILTER a1 != a2 AND b1 != b2\n",
    "            RETURN { author1: a1.name, author2: a2.name, book1: b1.title, book2: b2.title }\n",
    "\"\"\",\n",
    "    \n",
    "\"desc_32\": \"Find All Students Who Share Courses With Another Student\",\n",
    "    \n",
    "\"cypher_ex_32\":  \"\"\"\n",
    "MATCH (s1:Student)-[:ENROLLED_IN]->(c:Course)<-[:ENROLLED_IN]-(s2:Student)\n",
    "WHERE s1 <> s2\n",
    "RETURN s1.name, s2.name, c.title\n",
    "\"\"\",\n",
    "    \n",
    "\"aql_tr_32\": \"\"\"\n",
    "FOR s1 IN Student\n",
    "    FOR c IN 1..1 OUTBOUND s1 ENROLLED_IN\n",
    "        FOR s2 IN 1..1 INBOUND c ENROLLED_IN\n",
    "        FILTER s1 != s2\n",
    "        RETURN { student1: s1.name, student2: s2.name, course: c.title }\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create json dataset\n",
    "# store dataset.jsonl file in current working directory\n",
    "with open(\"dataset.jsonl\", \"w\") as f:\n",
    "    for idx in range(1, 32):\n",
    "        cy_k = f\"cypher_ex_{idx}\"\n",
    "        aq_k = f\"aql_tr_{idx}\"\n",
    "        prompt_dict = {\"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Marvin is an AI chatbot that specializes in translating cypher query to ArangoDB's AQL query\"},\n",
    "        {\"role\": \"user\", \"content\":f\"Translate the following cypher query {dataset[cy_k]} to ArangoDB AQL query\"},\n",
    "        {\"role\": \"assistant\", \"content\":f\"Equivalent ArangoDB AQL query is {dataset[aq_k]}\"}]}\n",
    "        f.write(json.dumps(prompt_dict) + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count tokens\n",
    "len(encoding.encode(dataset[\"cypher_ex_1\"] + dataset[\"aql_tr_1\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data \n",
    "\n",
    "Here we load the data for fine tuning the model with the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"dataset.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 31\n",
      "First example:\n",
      "{'role': 'system', 'content': \"Marvin is an AI chatbot that specializes in translating cypher query to ArangoDB's AQL query\"}\n",
      "{'role': 'user', 'content': \"Translate the following cypher query \\nMATCH (p:Person)-[:FRIEND]->(f:Person)\\nWHERE p.name = 'Alice'\\nRETURN p.name, f.name\\n to ArangoDB AQL query\"}\n",
      "{'role': 'assistant', 'content': \"Equivalent ArangoDB AQL query is \\nFOR p IN Person\\n    FOR f IN 1..1 OUTBOUND p FRIEND\\n    FILTER p.name == 'Alice'\\n    RETURN { pName: p.name, fName: f.name }\\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        if not content or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 114, 243\n",
      "mean / median: 153.48387096774192, 137.0\n",
      "p5 / p95: 120.0, 210.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 41, 116\n",
      "mean / median: 62.41935483870968, 53.0\n",
      "p5 / p95: 42.0, 97.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~4758 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~14274 tokens\n",
      "Esitmated charging price: 0.11419200000000002$\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "print(f\"Esitmated charging price: {n_epochs * n_billing_tokens_in_dataset * 0.001 * 0.0080}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning GPT-3.5 with our own Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY is None:\n",
    "    print(\"Fatal Error! need API key to proceed\")\n",
    "else:\n",
    "    openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"dataset.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-KHlQd6ZxfaF8XZplpuWFDMFF', bytes=18777, created_at=1713994020, filename='dataset.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# starts fine tuning\n",
    "job = client.fine_tuning.jobs.create(training_file=file.id, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cancel a job\n",
    "#openai.FineTuningJob.cancel(job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all jobs\n",
    "# for job in client.fine_tuning.jobs.list():\n",
    "#     print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='validating_files', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "jobstatus = openai.fine_tuning.jobs.retrieve(job.id)\n",
    "print(f\"\\nJob status: {jobstatus}\")\n",
    "SLEEP_TIME=0.5*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='validating_files', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='running', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='running', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='running', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='running', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='running', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='running', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='running', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='running', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "\n",
      "Job status: FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=[], seed=1176583671, status='running', trained_tokens=None, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n",
      "\n",
      "Sleeping 30.0 more seconds...\n",
      "Fine tuning took 6.50 minutes\n",
      "FineTuningJob(id='ftjob-FcthOU1lChzlmKV9Axbq2HRg', created_at=1713994024, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:arangodb::9HeX9b89', finished_at=1713994414, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-qxPkNPWF8DKL1WPIc5huNbv1', result_files=['file-G0jpTbEd20WyTJyXoti3JA1B'], seed=1176583671, status='succeeded', trained_tokens=14088, training_file='file-KHlQd6ZxfaF8XZplpuWFDMFF', validation_file=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while jobstatus.finished_at is None and jobstatus.status in [\"validating_files\",\"running\"]:\n",
    "    print(f\"\\nJob status: {jobstatus}\")\n",
    "    print(f\"\\nSleeping {SLEEP_TIME} more seconds...\")\n",
    "    time.sleep(SLEEP_TIME) # Sleep SLEEP_TIME seconds\n",
    "    jobstatus = openai.fine_tuning.jobs.retrieve(job.id)\n",
    "\n",
    "\n",
    "if jobstatus.error.code is not None or jobstatus.status != \"succeeded\":\n",
    "    print(f\"Fatal Error: {jobstatus},\\nFine-tuning job failed\")\n",
    "    raise SystemExit(\"Fatal error\")\n",
    "\n",
    "\n",
    "timetaken= jobstatus.finished_at - jobstatus.created_at\n",
    "    \n",
    "print(f\"Fine tuning took {timetaken/60:.2f} minutes, status {jobstatus.status}\")\n",
    "print(f\"{jobstatus}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Fine-Tuned Model\n",
    "These examples introduce new types of relationships, such as actors directing movies, customers sharing common interests, professors collaborating on research papers, and cities connected by high-speed railways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find All Stores and Their Products in a Specific Category\n",
    "# Find All Actors Who Directed Movies\n",
    "# Find All Customers Who Share a Common Interest\n",
    "# Find All Professors Who Collaborated on Research Papers\n",
    "# Find All Cities Connected by High-Speed Railways\n",
    "\n",
    "val_data = { \n",
    "\"val_1\": \"\"\"\n",
    "MATCH (s:Store)-[:SELLS]->(p:Product)-[:IN_CATEGORY]->(cat:Category)\n",
    "WHERE cat.name = 'Electronics'\n",
    "RETURN s.name, p.name\n",
    "\"\"\",\n",
    "\n",
    "\"ground_truth_1\": \"\"\"\n",
    "FOR s IN Store\n",
    "    FOR p IN 1..1 OUTBOUND s SELLS\n",
    "        FOR cat IN 1..1 INBOUND p IN_CATEGORY\n",
    "        FILTER cat.name == 'Electronics'\n",
    "        RETURN { store: s.name, product: p.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"val_2\": \"\"\"\n",
    "MATCH (a:Actor)-[:DIRECTED]->(m:Movie)\n",
    "RETURN a.name, m.title\n",
    "\"\"\",\n",
    "\n",
    "\"ground_truth_2\": \"\"\"\n",
    "FOR a IN Actor\n",
    "    FOR m IN 1..1 OUTBOUND a DIRECTED\n",
    "    RETURN { actor: a.name, movie: m.title }\n",
    "\"\"\",\n",
    "    \n",
    "\"val_3\":\"\"\"\n",
    "MATCH (c1:Customer)-[:HAS_INTEREST]->(i:Interest)<-[:HAS_INTEREST]-(c2:Customer)\n",
    "WHERE c1 <> c2\n",
    "RETURN c1.name, c2.name, i.name\n",
    "\"\"\",\n",
    "\n",
    "\"ground_truth_3\": \"\"\"\n",
    "FOR c1 IN Customer\n",
    "    FOR i IN 1..1 OUTBOUND c1 HAS_INTEREST\n",
    "        FOR c2 IN 1..1 INBOUND i HAS_INTEREST\n",
    "        FILTER c1 != c2\n",
    "        RETURN { customer1: c1.name, customer2: c2.name, interest: i.name }\n",
    "\"\"\",\n",
    "    \n",
    "\"val_4\":\"\"\"\n",
    "MATCH (p1:Professor)-[:WROTE]->(r:ResearchPaper)<-[:WROTE]-(p2:Professor)\n",
    "WHERE p1 <> p2\n",
    "RETURN p1.name, p2.name, r.title\n",
    "\"\"\",\n",
    "    \n",
    "\"ground_truth_4\": \"\"\"\n",
    "FOR p1 IN Professor\n",
    "    FOR r IN 1..1 OUTBOUND p1 WROTE\n",
    "        FOR p2 IN 1..1 OUTBOUND r WROTE\n",
    "        FILTER p1 != p2\n",
    "        RETURN { professor1: p1.name, professor2: p2.name, researchPaper: r.title }\n",
    "\n",
    "\"\"\",\n",
    "    \n",
    "\"val_5\": \"\"\"\n",
    "MATCH (c1:City)-[:CONNECTED_BY]->(hsr:HighSpeedRailway)<-[:CONNECTED_BY]-(c2:City)\n",
    "WHERE c1 <> c2\n",
    "RETURN c1.name, c2.name, hsr.name\n",
    "\"\"\",\n",
    "    \n",
    "\"ground_truth_5\": \"\"\"\n",
    "FOR c1 IN City\n",
    "    FOR hsr IN 1..1 OUTBOUND c1 CONNECTED_BY\n",
    "        FOR c2 IN 1..1 INBOUND hsr CONNECTED_BY\n",
    "        FILTER c1 != c2\n",
    "        RETURN { city1: c1.name, city2: c2.name, highSpeedRailway: hsr.name  }\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0125:arangodb::9HeX9b89\n"
     ]
    }
   ],
   "source": [
    "print(jobstatus.fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if jobstatus.fine_tuned_model is None:\n",
    "    SystemExit(\"Fatal unable to get fine-tuned model, tuning job failed\")\n",
    "    \n",
    "# validate on new data\n",
    "val_cypher = val_data[\"val_5\"]\n",
    "completion = client.chat.completions.create( model=jobstatus.fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Marvin is an AI chatbot that specializes in translating cypher query to ArangoDB's AQL query\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Translate the following cypher query {val_cypher} to ArangoDB AQL query\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equivalent ArangoDB AQL query is \n",
      "FOR c1 IN City\n",
      "    FOR hsr IN 1..1 OUTBOUND c1 CONNECTED_BY\n",
      "        FOR c2 IN 1..1 INBOUND hsr CONNECTED_BY\n",
      "        FILTER c1 != c2\n",
      "        RETURN { city1: c1.name, city2: c2.name, railway: hsr.name }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# result from fine-tune model\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Chatbot Demo\n",
    "This is a sample visual interface for running the queries you can always run it programmatically using the API against the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cypher_to_aql(user_input):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"Marvin is an AI chatbot that specializes in translating cypher query to ArangoDB's AQL query\"},]\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    completion = client.chat.completions.create(\n",
    "      model=jobstatus.fine_tuned_model,\n",
    "      messages= messages,\n",
    "    )\n",
    "    reply = completion.choices[0].message.content\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = gradio.components.Textbox(lines=7, label=\"Chat with Fine-Tuned GPT-3.5\")\n",
    "outputs = gradio.components.Textbox(lines=7,label=\"Fine-Tuned GPT-3.5 Reply\")\n",
    "demo = gradio.Interface(fn=cypher_to_aql, inputs = inputs, outputs = outputs, title = \"Cypher to ArangoDB AQL Chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://51af4e627d220f3ae2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://51af4e627d220f3ae2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
